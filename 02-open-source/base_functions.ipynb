{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base functions\n",
    "> Functions to complete the RAG process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify if exist all the necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "from pathlib import Path\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "# Define the relative path to the 'data' directory and the document name\n",
    "data_dir = Path('..', 'data')\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "document_url = \"https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\"\n",
    "file_name = document_url.split('/')[-1]\n",
    "document_path = Path(data_dir, file_name)\n",
    "\n",
    "\n",
    "if not document_path.is_file():\n",
    "    result = subprocess.run(['wget', document_url, '-O', str(document_path)], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"{file_name} download successful\")\n",
    "    else:\n",
    "        print(f\"Error occurred downloading {file_name}: {result.stderr}\") \n",
    "\n",
    "with open(document_path, 'rt') as f_in:\n",
    "    documents_raw = json.load(f_in)\n",
    "\n",
    "documents = []\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "minsearch_url = \"https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/minsearch.py\"\n",
    "file_name = minsearch_url.split('/')[-1]\n",
    "path = Path('.', file_name)\n",
    "\n",
    "if not path.is_file():\n",
    "    result = subprocess.run(['wget', minsearch_url], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(f\"{file_name} download successful\")\n",
    "    else:\n",
    "        print(f\"Error occurred downloading {file_name}: {result.stderr}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we want to download the base document file instead to use the saved in disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search index using TF-IDF and cosine similarity for text fields and exact matching for keyword fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x70bafc14f400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from minsearch import Index\n",
    "\n",
    "index = Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp'}\n",
      "{'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.', 'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp'}\n",
      "{'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.', 'section': 'General course-related questions', 'question': 'Course - Can I get support if I take the course in the self-paced mode?', 'course': 'data-engineering-zoomcamp'}\n"
     ]
    }
   ],
   "source": [
    "query = \"Can I join the course if it has already started?\"\n",
    "\n",
    "filter_dict = {\"course\": \"data-engineering-zoomcamp\"}\n",
    "boost_dict = {\"question\": 3, \"section\": 0.5}\n",
    "minsearch_results = index.search(query, \n",
    "                       filter_dict, \n",
    "                       boost_dict, \n",
    "                       num_results=3)\n",
    "\n",
    "for result in minsearch_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_index_search(query: str, filter_dict: dict={}, boost_dict: dict={}, num_results: int=3):\n",
    "    results = index.search(query, filter_dict, boost_dict, num_results)\n",
    "    return results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\", 'section': 'General course-related questions', 'question': 'Course - Can I still join the course after the start date?', 'course': 'data-engineering-zoomcamp'}\n",
      "{'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.', 'section': 'General course-related questions', 'question': 'Course - Can I follow the course after it finishes?', 'course': 'data-engineering-zoomcamp'}\n",
      "{'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.', 'section': 'General course-related questions', 'question': 'Course - Can I get support if I take the course in the self-paced mode?', 'course': 'data-engineering-zoomcamp'}\n"
     ]
    }
   ],
   "source": [
    "query = \"Can I join the course if it has already started?\"\n",
    "filter_dict = {\"course\": \"data-engineering-zoomcamp\"}\n",
    "boost_dict = {\"question\": 3, \"section\": 0.5}\n",
    "\n",
    "minsearch_results = minsearch_index_search(query, filter_dict, boost_dict)\n",
    "\n",
    "for result in minsearch_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector storage (ElasticSearch)\n",
    "\n",
    "- How to create a docker container for ElasticSearch:\n",
    "\n",
    "```bash\n",
    "docker run -d \\\n",
    "    --name elasticsearch \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3\n",
    "```\n",
    "\n",
    "- How to verify if it is running, execute in a `terminal`:\n",
    "\n",
    "```bash\n",
    "curl http://localhost:9200\n",
    "```\n",
    "\n",
    "- This is the index setting:  \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "- This is a query example:  \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a1e79279a94ffb9b0615ea29264b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index 'homework-course' has been created.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0,\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"homework-course\"\n",
    "# Check if the index exists\n",
    "if es_client.indices.exists(index=index_name):\n",
    "    print(f\"The index '{index_name}' already exists.\")\n",
    "else:\n",
    "    es_client.indices.create(index=index_name, body=index_settings)\n",
    "    for doc in tqdm(documents):\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    \n",
    "    print(f\"The index '{index_name}' has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(index_name: str, query: str, fields: list[str], filter_course: str, num_results: int=5):\n",
    "    search_query = {\n",
    "        \"size\": num_results,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": fields,\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": filter_course\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    result_docs = [hit['_source'] for hit in response['hits']['hits']]\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Yes, the slack channel remains open and you can ask questions there. But always sDocker containers exit code w search the channel first and second, check the FAQ (this document), most likely all your questions are already answered here.\\nYou can also tag the bot @ZoomcampQABot to help you conduct the search, but don’t rely on its answers 100%, it is pretty good though.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - Can I get support if I take the course in the self-paced mode?',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%script false --no-raise-error\n",
    "\n",
    "index_name = \"homework-course\"\n",
    "query = \"I just discovered the course. Can I still join it?\"\n",
    "fields = [\"question^3\", \"text\", \"section\"]\n",
    "filter_course=\"data-engineering-zoomcamp\"\n",
    "elastic_search(index_name, query, fields, filter_course)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the prompt, LLM and RAG functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_prompt(query: str, search_result: str):\n",
    "    user_prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context_template = \"\"\"\n",
    "S: {section}\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context= \"\"\n",
    "    \n",
    "    for doc in search_result:\n",
    "        context += f\"{context_template.format(section=doc['section'], question=doc['question'], text=doc['text'])}\\n\\n\"\n",
    "\n",
    "    user_prompt = user_prompt_template.format(question=query, context=context).strip()\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"homework-course\"\n",
    "query=\"How do I execute a command in a running docker container?\"\n",
    "fields = [\"question^4\", \"text\", \"section\"]\n",
    "filter_course=\"machine-learning-zoomcamp\"\n",
    "search_result = elastic_search(index_name, query, fields, filter_course, num_results=3)\n",
    "prompt = build_user_prompt(query, search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION.\n",
      "\n",
      "QUESTION: How do I execute a command in a running docker container?\n",
      "\n",
      "CONTEXT:\n",
      "S: 5. Deploying Machine Learning Models\n",
      "Q: How do I debug a docker container?\n",
      "A: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\n",
      "docker run -it --entrypoint bash <image>\n",
      "If the container is already running, execute a command in the specific container:\n",
      "docker ps (find the container-id)\n",
      "docker exec -it <container-id> bash\n",
      "(Marcos MJD)\n",
      "\n",
      "S: 5. Deploying Machine Learning Models\n",
      "Q: How do I copy files from my local machine to docker container?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "To copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\n",
      "docker cp /path/to/local/file_or_directory container_id:/path/in/container\n",
      "Hrithik Kumar Advani\n",
      "\n",
      "S: 5. Deploying Machine Learning Models\n",
      "Q: How do I copy files from a different folder into docker container’s working directory?\n",
      "A: You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\n",
      "In the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\n",
      "COPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\t\t\t\t\t\t\t\t\t\t\tGopakumar Gopinathan\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "open_source = True\n",
    "\n",
    "if open_source:  \n",
    "    client = OpenAI(\n",
    "        base_url='http://localhost:11434/v1/',\n",
    "        api_key='ollama',\n",
    "    )\n",
    "else:\n",
    "    client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(user_prompt: str, model: str=\"gpt-3.5-turbo\"):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages= [\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_elastic(index_name: str, query: str, fields: list[str], filter_course: str, num_results: int, model ):\n",
    "    search_result = elastic_search(index_name, query, fields, filter_course, num_results)\n",
    "    user_prompt = build_user_prompt(query, search_result)\n",
    "    answer = llm(user_prompt, model)\n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' To execute a command in a running docker container, you can use the `docker exec` command. If the container is already running, you can find the container ID using `docker ps`, and then execute a command by appending the container ID followed by `-it bash`. The syntax would look like:\\n\\n```\\ndocker exec -it <container-id> bash\\n```'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"homework-course\"\n",
    "query=\"How do I execute a command in a running docker container?\"\n",
    "fields = [\"question^4\", \"text\", \"section\"]\n",
    "filter_course=\"machine-learning-zoomcamp\"\n",
    "num_results = 3\n",
    "model = \"phi3\"\n",
    "answer = rag_elastic(index_name, query, fields, filter_course, num_results, model)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes to make a backup and restore of elasticsearch index\n",
    "\n",
    "- Open a bash session in the elasticsearch container\n",
    "```bash\n",
    "docker exec -it elasticsearch bash\n",
    "```\n",
    "\n",
    "- Add path.repo configuration\n",
    "```bash\n",
    "echo path.repo: [\"/usr/share/elasticsearch/backup\"] >> /usr/share/elasticsearch/config/elasticsearch.yml\n",
    "exit\n",
    "```\n",
    "\n",
    "- Restart container and verify it was created correctly\n",
    "```bash\n",
    "docker restart elasticsearch\n",
    "curl -X GET \"localhost:9200/_snapshot/my_backup?pretty\"\n",
    "```\n",
    "\n",
    "- Create the snapshot\n",
    "```bash\n",
    "curl -X PUT \"localhost:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true\" -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "  \"indices\": \"your_index_name\",\n",
    "  \"ignore_unavailable\": true,\n",
    "  \"include_global_state\": false\n",
    "}\n",
    "'\n",
    "```\n",
    "\n",
    "- Copy the backup to my machine\n",
    "```bash\n",
    "docker cp elasticsearch:/usr/share/elasticsearch/backup /path/to/local\n",
    "```\n",
    "\n",
    "- Now create the new one with docker-compose:\n",
    "```bash\n",
    "docker compose up -d\n",
    "```\n",
    "\n",
    "- Add de path.repo configuration in the new one, same as before.\n",
    "```bash\n",
    "docker exec -it new_elasticsearch bash\n",
    "echo path.repo: [\"/usr/share/elasticsearch/backup\"] >> /usr/share/elasticsearch/config/elasticsearch.yml\n",
    "```\n",
    "\n",
    "- Restart the docker container and copy the snapshot in it\n",
    "```bash\n",
    "docker restart new_elasticsearch\n",
    "docker cp /path/to/local/backup new_elasticsearch:/usr/share/elasticsearch\n",
    "```\n",
    "\n",
    "- Register the Snapshot Repository in the New Container.\n",
    "```bash\n",
    "curl -X PUT \"localhost:9200/_snapshot/my_backup\" -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "  \"type\": \"fs\",\n",
    "  \"settings\": {\n",
    "    \"location\": \"/usr/share/elasticsearch/backup\"\n",
    "  }\n",
    "}\n",
    "'\n",
    "```\n",
    "\n",
    "- Verify if it exists\n",
    "```bash\n",
    "curl -X GET \"localhost:9200/_snapshot/my_backup/snapshot_1?pretty\"\n",
    "```\n",
    "\n",
    "- Restore the snapshot\n",
    "```bash\n",
    "curl -X POST \"localhost:9200/_snapshot/my_backup/snapshot_1/_restore\" -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "  \"indices\": \"your_index_name\",\n",
    "  \"ignore_unavailable\": true,\n",
    "  \"include_global_state\": false\n",
    "}\n",
    "'\n",
    "```\n",
    "\n",
    "- Extra point: If you want to change the original index name by other when you restore the snapshot:\n",
    "```bash\n",
    "curl -X POST \"localhost:9200/_snapshot/my_backup/snapshot_1/_restore?pretty\" -H 'Content-Type: application/json' -d'\n",
    "{\n",
    "  \"indices\": \"old_index\",\n",
    "  \"ignore_unavailable\": true,\n",
    "  \"include_global_state\": false,\n",
    "  \"rename_pattern\": \"old_index\",\n",
    "  \"rename_replacement\": \"new_index\"\n",
    "}\n",
    "'\n",
    "```\n",
    "\n",
    "- Show your indexes:\n",
    "```bash\n",
    "curl -X GET \"localhost:9200/_cat/indices?v\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
